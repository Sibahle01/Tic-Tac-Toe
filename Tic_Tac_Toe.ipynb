{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibahle01/Tic-Tac-Toe/blob/main/Tic_Tac_Toe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yy4TI6OdH3Ym"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3), dtype=int)\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.board[:] = 0\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return tuple(self.board.reshape(9))\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [i for i in range(9) if self.board.reshape(9)[i] == 0]\n",
        "\n",
        "    def step(self, action, player):\n",
        "        if self.done:\n",
        "            return self.get_state(), 0, True\n",
        "\n",
        "        row, col = divmod(action, 3)\n",
        "        if self.board[row, col] != 0:\n",
        "            return self.get_state(), -10, True  # illegal move\n",
        "\n",
        "        self.board[row, col] = player\n",
        "\n",
        "        if self.check_winner(player):\n",
        "            self.done = True\n",
        "            self.winner = player\n",
        "            return self.get_state(), 1, True\n",
        "\n",
        "        if not self.available_actions():\n",
        "            self.done = True\n",
        "            self.winner = 0\n",
        "            return self.get_state(), 0.5, True  # draw\n",
        "\n",
        "        return self.get_state(), 0, False\n",
        "\n",
        "    def check_winner(self, player):\n",
        "        for i in range(3):\n",
        "            if all(self.board[i, :] == player) or all(self.board[:, i] == player):\n",
        "                return True\n",
        "        if all(np.diag(self.board) == player) or all(np.diag(np.fliplr(self.board)) == player):\n",
        "            return True\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T1sL67lXH_AG"
      },
      "outputs": [],
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.9995, epsilon_min=0.1):\n",
        "        self.q_table = {}\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "\n",
        "    def get_qs(self, state):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = np.zeros(9)\n",
        "        return self.q_table[state]\n",
        "\n",
        "    def choose_action(self, state, available_actions):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        qs = self.get_qs(state)\n",
        "        filtered_qs = [(i, qs[i]) for i in available_actions]\n",
        "        return max(filtered_qs, key=lambda x: x[1])[0]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done, available_actions):\n",
        "        old_q = self.get_qs(state)[action]\n",
        "        next_max_q = 0 if done else max(self.get_qs(next_state)[a] for a in available_actions)\n",
        "        self.q_table[state][action] += self.alpha * (reward + self.gamma * next_max_q - old_q)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MvYdvHPhIDDq"
      },
      "outputs": [],
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.9995, epsilon_min=0.1):\n",
        "        self.q_table = {}  # maps state -> action values\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "\n",
        "    def get_qs(self, state):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = np.zeros(9)\n",
        "        return self.q_table[state]\n",
        "\n",
        "    def choose_action(self, state, available_actions):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        qs = self.get_qs(state)\n",
        "        filtered_qs = [(i, qs[i]) for i in available_actions]\n",
        "        return max(filtered_qs, key=lambda x: x[1])[0]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done, available_actions):\n",
        "        old_q = self.get_qs(state)[action]\n",
        "        next_max_q = 0 if done else max(self.get_qs(next_state)[a] for a in available_actions)\n",
        "        self.q_table[state][action] += self.alpha * (reward + self.gamma * next_max_q - old_q)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O9RmqxKIr6D",
        "outputId": "e843a3fc-f40f-497c-e5ca-eaab9b938248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1000, Epsilon: 0.132\n",
            "Episode 2000, Epsilon: 0.100\n",
            "Episode 3000, Epsilon: 0.100\n",
            "Episode 4000, Epsilon: 0.100\n",
            "Episode 5000, Epsilon: 0.100\n",
            "Episode 6000, Epsilon: 0.100\n",
            "Episode 7000, Epsilon: 0.100\n",
            "Episode 8000, Epsilon: 0.100\n",
            "Episode 9000, Epsilon: 0.100\n",
            "Episode 10000, Epsilon: 0.100\n"
          ]
        }
      ],
      "source": [
        "env = TicTacToe()\n",
        "agent = QLearningAgent()\n",
        "\n",
        "episodes = 10000\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        available = env.available_actions()\n",
        "        action = agent.choose_action(state, available)\n",
        "        next_state, reward, done = env.step(action, 1)\n",
        "\n",
        "        if not done:\n",
        "            # Opponent (random)\n",
        "            opponent_action = random.choice(env.available_actions())\n",
        "            next_state, opp_reward, done = env.step(opponent_action, -1)\n",
        "            if done:\n",
        "                reward = -1 if env.winner == -1 else 0.5\n",
        "\n",
        "        agent.learn(state, action, reward, next_state, done, env.available_actions())\n",
        "        state = next_state\n",
        "\n",
        "    if (ep + 1) % 1000 == 0:\n",
        "        print(f\"Episode {ep+1}, Epsilon: {agent.epsilon:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFj4mSGSIxX-",
        "outputId": "7998e81b-bf71-4ed4-e613-3a8edaba8e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1000: Wins=692, Losses=192, Draws=116, Epsilon=0.139\n",
            "Episode 2000: Wins=854, Losses=63, Draws=83, Epsilon=0.100\n",
            "Episode 3000: Wins=887, Losses=37, Draws=76, Epsilon=0.100\n",
            "Episode 4000: Wins=880, Losses=42, Draws=78, Epsilon=0.100\n",
            "Episode 5000: Wins=866, Losses=49, Draws=85, Epsilon=0.100\n",
            "Episode 6000: Wins=885, Losses=37, Draws=78, Epsilon=0.100\n",
            "Episode 7000: Wins=897, Losses=43, Draws=60, Epsilon=0.100\n",
            "Episode 8000: Wins=898, Losses=38, Draws=64, Epsilon=0.100\n",
            "Episode 9000: Wins=888, Losses=44, Draws=68, Epsilon=0.100\n",
            "Episode 10000: Wins=882, Losses=29, Draws=89, Epsilon=0.100\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# --- 1. Environment ---\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3), dtype=int)  # 0 = empty, 1 = X, -1 = O\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.board[:] = 0\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return tuple(self.board.reshape(9))\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [i for i in range(9) if self.board.reshape(9)[i] == 0]\n",
        "\n",
        "    def step(self, action, player):\n",
        "        if self.done:\n",
        "            return self.get_state(), 0, True\n",
        "\n",
        "        row, col = divmod(action, 3)\n",
        "        if self.board[row, col] != 0:\n",
        "            return self.get_state(), -10, True\n",
        "\n",
        "        self.board[row, col] = player\n",
        "\n",
        "        if self.check_winner(player):\n",
        "            self.done = True\n",
        "            self.winner = player\n",
        "            return self.get_state(), 1, True\n",
        "\n",
        "        if not self.available_actions():\n",
        "            self.done = True\n",
        "            self.winner = 0\n",
        "            return self.get_state(), 0.5, True  # draw\n",
        "\n",
        "        return self.get_state(), 0, False\n",
        "\n",
        "    def check_winner(self, player):\n",
        "        for i in range(3):\n",
        "            if all(self.board[i, :] == player) or all(self.board[:, i] == player):\n",
        "                return True\n",
        "        if all(np.diag(self.board) == player) or all(np.diag(np.fliplr(self.board)) == player):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# --- 2. Q-learning Agent ---\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.9995, epsilon_min=0.1):\n",
        "        self.q_table = {}\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "\n",
        "    def get_qs(self, state):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = np.zeros(9)\n",
        "        return self.q_table[state]\n",
        "\n",
        "    def choose_action(self, state, available_actions):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        qs = self.get_qs(state)\n",
        "        filtered_qs = [(i, qs[i]) for i in available_actions]\n",
        "        return max(filtered_qs, key=lambda x: x[1])[0]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done, available_actions):\n",
        "        old_q = self.get_qs(state)[action]\n",
        "        next_max_q = 0 if done else max(self.get_qs(next_state)[a] for a in available_actions)\n",
        "        self.q_table[state][action] += self.alpha * (reward + self.gamma * next_max_q - old_q)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "# --- 3. Training Loop ---\n",
        "env = TicTacToe()\n",
        "agent = QLearningAgent()\n",
        "\n",
        "episodes = 10000\n",
        "wins = 0\n",
        "losses = 0\n",
        "draws = 0\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        available = env.available_actions()\n",
        "        action = agent.choose_action(state, available)\n",
        "        next_state, reward, done = env.step(action, 1)\n",
        "\n",
        "        if not done:\n",
        "            opponent_action = random.choice(env.available_actions())\n",
        "            next_state, opp_reward, done = env.step(opponent_action, -1)\n",
        "            if done:\n",
        "                reward = -1 if env.winner == -1 else 0.5\n",
        "\n",
        "        agent.learn(state, action, reward, next_state, done, env.available_actions())\n",
        "        state = next_state\n",
        "\n",
        "    if env.winner == 1:\n",
        "        wins += 1\n",
        "    elif env.winner == -1:\n",
        "        losses += 1\n",
        "    else:\n",
        "        draws += 1\n",
        "\n",
        "    if (ep + 1) % 1000 == 0:\n",
        "        print(f\"Episode {ep+1}: Wins={wins}, Losses={losses}, Draws={draws}, Epsilon={agent.epsilon:.3f}\")\n",
        "        wins = losses = draws = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YcyDqF_JOC1",
        "outputId": "ae592b60-5237-452d-d0c5-f6da51f31d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are O (player -1). The agent is X (player 1).\n",
            "\n",
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter your move (0-8): 1\n",
            "\n",
            "Agent chooses: 0\n",
            "X|O| \n",
            "-----\n",
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter your move (0-8): 7\n",
            "\n",
            "Agent chooses: 2\n",
            "X|O|X\n",
            "-----\n",
            " | | \n",
            "-----\n",
            " |O| \n",
            "-----\n",
            "Enter your move (0-8): 4\n",
            "X|O|X\n",
            "-----\n",
            " |O| \n",
            "-----\n",
            " |O| \n",
            "-----\n",
            "You win! üéâ\n"
          ]
        }
      ],
      "source": [
        "def print_board(state):\n",
        "    symbols = {1: 'X', -1: 'O', 0: ' '}\n",
        "    board = np.array(state).reshape(3, 3)\n",
        "    for row in board:\n",
        "        print('|'.join(symbols[val] for val in row))\n",
        "        print('-' * 5)\n",
        "\n",
        "def play_against_agent(agent):\n",
        "    game = TicTacToe()\n",
        "    state = game.reset()\n",
        "    print(\"You are O (player -1). The agent is X (player 1).\\n\")\n",
        "\n",
        "    while not game.done:\n",
        "        print_board(state)\n",
        "        try:\n",
        "            user_move = int(input(\"Enter your move (0-8): \"))\n",
        "            if user_move not in game.available_actions():\n",
        "                print(\"Invalid move. Try again.\")\n",
        "                continue\n",
        "        except ValueError:\n",
        "            print(\"Please enter a number between 0 and 8.\")\n",
        "            continue\n",
        "\n",
        "        _, _, done = game.step(user_move, -1)\n",
        "        state = game.get_state()\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Agent's turn\n",
        "        available = game.available_actions()\n",
        "        action = agent.choose_action(state, available)\n",
        "        print(f\"\\nAgent chooses: {action}\")\n",
        "        _, _, done = game.step(action, 1)\n",
        "        state = game.get_state()\n",
        "\n",
        "    print_board(state)\n",
        "    if game.winner == 1:\n",
        "        print(\"Agent wins! üß†\")\n",
        "    elif game.winner == -1:\n",
        "        print(\"You win! üéâ\")\n",
        "    else:\n",
        "        print(\"It's a draw ü§ù\")\n",
        "\n",
        "# Run the game\n",
        "play_against_agent(agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well... atleast it knows how to play and where\n"
      ],
      "metadata": {
        "id": "Tan9IIf-7Vmg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-WzjID9jY0V"
      },
      "source": [
        "#Lets Improve Implement Q-Learning Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "77vUoKY_fy1v",
        "outputId": "c5aaf008-9519-4e56-9ce3-7b102b9bf306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20000/20000\n",
            "Win rate: 95.50%\n",
            "Loss rate: 0.80%\n",
            "Draw rate: 3.70%\n",
            "Exploration rate: 0.010\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete! Now you can play against the agent.\n",
            "You are O (second player). The agent is X (first player).\n",
            "Enter moves as numbers corresponding to board positions:\n",
            "\n",
            "  0 1 2\n",
            "0 0 1 2\n",
            "1 3 4 5\n",
            "2 6 7 8\n",
            "Current player: X\n",
            "\n",
            "Agent's turn...\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 2\n",
            "1 3 4 5\n",
            "2 6 7 8\n",
            "Current player: O\n",
            "\n",
            "Your move (enter position number): 2\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 3 4 5\n",
            "2 6 7 8\n",
            "Current player: X\n",
            "\n",
            "Agent's turn...\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 3 4 5\n",
            "2 X 7 8\n",
            "Current player: O\n",
            "\n",
            "Your move (enter position number): 3\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 O 4 5\n",
            "2 X 7 8\n",
            "Current player: X\n",
            "\n",
            "Agent's turn...\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 O X 5\n",
            "2 X 7 8\n",
            "Current player: O\n",
            "\n",
            "Your move (enter position number): 7\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 O X 5\n",
            "2 X O 8\n",
            "Current player: X\n",
            "\n",
            "Agent's turn...\n",
            "\n",
            "  0 1 2\n",
            "0 X 1 O\n",
            "1 O X 5\n",
            "2 X O X\n",
            "Current player: X\n",
            "\n",
            "Agent (X) wins! üß†\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "from time import sleep\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the game board and state\"\"\"\n",
        "        self.board = np.zeros((3, 3), dtype=int)\n",
        "        self.current_player = 1\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Get the current game state as a hashable tuple\"\"\"\n",
        "        return tuple(self.board.reshape(9))\n",
        "\n",
        "    def available_actions(self):\n",
        "        \"\"\"Get list of available moves (0-8)\"\"\"\n",
        "        return [i for i in range(9) if self.board.reshape(9)[i] == 0]\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Execute a move and return (new_state, reward, done)\n",
        "\n",
        "        Args:\n",
        "            action: Integer 0-8 representing board position\n",
        "\n",
        "        Returns:\n",
        "            tuple: (new_state, reward, done)\n",
        "        \"\"\"\n",
        "        if self.done:\n",
        "            return self.get_state(), 0, True\n",
        "\n",
        "        row, col = divmod(action, 3)\n",
        "\n",
        "        # Illegal move penalty\n",
        "        if self.board[row, col] != 0:\n",
        "            self.done = True\n",
        "            return self.get_state(), -10, True\n",
        "\n",
        "        # Make the move\n",
        "        self.board[row, col] = self.current_player\n",
        "\n",
        "        # Check for winner\n",
        "        if self._check_winner(self.current_player):\n",
        "            self.done = True\n",
        "            self.winner = self.current_player\n",
        "            reward = 1 if self.current_player == 1 else -1\n",
        "            return self.get_state(), reward, True\n",
        "\n",
        "        # Check for draw\n",
        "        if len(self.available_actions()) == 0:\n",
        "            self.done = True\n",
        "            return self.get_state(), 0.5, True\n",
        "\n",
        "        # Switch player\n",
        "        self.current_player *= -1\n",
        "        return self.get_state(), 0, False\n",
        "\n",
        "    def _check_winner(self, player):\n",
        "        \"\"\"Check if the specified player has won\"\"\"\n",
        "        board = self.board\n",
        "        # Check rows and columns\n",
        "        for i in range(3):\n",
        "            if all(board[i, :] == player) or all(board[:, i] == player):\n",
        "                return True\n",
        "        # Check diagonals\n",
        "        if (board[0, 0] == board[1, 1] == board[2, 2] == player or\n",
        "            board[0, 2] == board[1, 1] == board[2, 0] == player):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"Display the current board state with move numbers\"\"\"\n",
        "        symbols = {1: 'X', -1: 'O', 0: ' '}\n",
        "        print(\"\\n  0 1 2\")\n",
        "        for i in range(3):\n",
        "            row = []\n",
        "            for j in range(3):\n",
        "                if self.board[i, j] == 0:\n",
        "                    row.append(str(i*3 + j))  # Show position numbers for empty cells\n",
        "                else:\n",
        "                    row.append(symbols[self.board[i, j]])\n",
        "            print(f\"{i} {' '.join(row)}\")\n",
        "        print(f\"Current player: {'X' if self.current_player == 1 else 'O'}\\n\")\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0,\n",
        "                 epsilon_decay=0.9995, epsilon_min=0.01):\n",
        "        \"\"\"\n",
        "        Initialize Q-learning agent\n",
        "\n",
        "        Args:\n",
        "            alpha: Learning rate (0-1)\n",
        "            gamma: Discount factor (0-1)\n",
        "            epsilon: Exploration rate (0-1)\n",
        "            epsilon_decay: Rate at which epsilon decreases\n",
        "            epsilon_min: Minimum exploration rate\n",
        "        \"\"\"\n",
        "        self.q_table = defaultdict(lambda: np.zeros(9))\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.training_history = []\n",
        "\n",
        "    def get_q_values(self, state):\n",
        "        \"\"\"Get Q-values for all actions in given state\"\"\"\n",
        "        return self.q_table[state]\n",
        "\n",
        "    def choose_action(self, state, available_actions, training=True):\n",
        "        \"\"\"\n",
        "        Choose action using Œµ-greedy policy\n",
        "\n",
        "        Args:\n",
        "            state: Current game state\n",
        "            available_actions: List of legal moves\n",
        "            training: Whether to use exploration\n",
        "\n",
        "        Returns:\n",
        "            int: Chosen action (0-8)\n",
        "        \"\"\"\n",
        "        if training and np.random.random() < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        q_values = self.get_q_values(state)\n",
        "\n",
        "        filtered_qs = {a: q_values[a] for a in available_actions}\n",
        "        return max(filtered_qs.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done, available_actions):\n",
        "        \"\"\"\n",
        "        Update Q-values using Q-learning update rule\n",
        "\n",
        "        Args:\n",
        "            state: Current state\n",
        "            action: Taken action\n",
        "            reward: Received reward\n",
        "            next_state: Resulting state\n",
        "            done: Whether episode ended\n",
        "            available_actions: Legal moves in next state\n",
        "        \"\"\"\n",
        "        current_q = self.q_table[state][action]\n",
        "\n",
        "        # Calculate max Q for next state\n",
        "        if done:\n",
        "            next_max_q = 0\n",
        "        else:\n",
        "            next_max_q = max(self.q_table[next_state][a] for a in available_actions)\n",
        "\n",
        "        # Bellman equation update\n",
        "        new_q = current_q + self.alpha * (reward + self.gamma * next_max_q - current_q)\n",
        "        self.q_table[state][action] = new_q\n",
        "\n",
        "        # Decay exploration rate\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def record_episode(self, episode, wins, losses, draws):\n",
        "        \"\"\"Record training statistics\"\"\"\n",
        "        self.training_history.append({\n",
        "            'episode': episode,\n",
        "            'wins': wins,\n",
        "            'losses': losses,\n",
        "            'draws': draws,\n",
        "            'epsilon': self.epsilon\n",
        "        })\n",
        "\n",
        "    def plot_training(self):\n",
        "        \"\"\"Plot training progress\"\"\"\n",
        "        if not self.training_history:\n",
        "            print(\"No training data to plot\")\n",
        "            return\n",
        "\n",
        "        eps = [x['episode'] for x in self.training_history]\n",
        "        win_rates = [x['wins']/100 for x in self.training_history]\n",
        "        loss_rates = [x['losses']/100 for x in self.training_history]\n",
        "        draw_rates = [x['draws']/100 for x in self.training_history]\n",
        "        epsilons = [x['epsilon'] for x in self.training_history]\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Win/Loss/Draw rates\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(eps, win_rates, label='Win Rate')\n",
        "        plt.plot(eps, loss_rates, label='Loss Rate')\n",
        "        plt.plot(eps, draw_rates, label='Draw Rate')\n",
        "        plt.title('Training Performance')\n",
        "        plt.xlabel('Episodes (x100)')\n",
        "        plt.ylabel('Rate')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Exploration rate\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(eps, epsilons, color='red')\n",
        "        plt.title('Exploration Rate (Œµ)')\n",
        "        plt.xlabel('Episodes (x100)')\n",
        "        plt.ylabel('Œµ')\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def train_agent(episodes=10000, print_interval=1000):\n",
        "    \"\"\"Train the agent against a random opponent\"\"\"\n",
        "    env = TicTacToe()\n",
        "    agent = QLearningAgent()\n",
        "\n",
        "    # Track performance\n",
        "    stats = {'wins': 0, 'losses': 0, 'draws': 0}\n",
        "\n",
        "    for episode in range(1, episodes + 1):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "\n",
        "            available = env.available_actions()\n",
        "            action = agent.choose_action(state, available)\n",
        "            next_state, reward, done = env.step(action)\n",
        "\n",
        "\n",
        "            if not done:\n",
        "                # Random opponent's turn (O)\n",
        "                opp_action = random.choice(env.available_actions())\n",
        "                next_state, opp_reward, done = env.step(opp_action)\n",
        "\n",
        "\n",
        "                if done:\n",
        "                    reward = -1 if env.winner == -1 else 0.5\n",
        "\n",
        "\n",
        "            agent.learn(state, action, reward, next_state, done, env.available_actions())\n",
        "            state = next_state\n",
        "\n",
        "        # Record results\n",
        "        if env.winner == 1:\n",
        "            stats['wins'] += 1\n",
        "        elif env.winner == -1:\n",
        "            stats['losses'] += 1\n",
        "        else:\n",
        "            stats['draws'] += 1\n",
        "\n",
        "        # Print and reset stats periodically\n",
        "        if episode % print_interval == 0:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"Episode {episode}/{episodes}\")\n",
        "            print(f\"Win rate: {stats['wins']/print_interval:.2%}\")\n",
        "            print(f\"Loss rate: {stats['losses']/print_interval:.2%}\")\n",
        "            print(f\"Draw rate: {stats['draws']/print_interval:.2%}\")\n",
        "            print(f\"Exploration rate: {agent.epsilon:.3f}\")\n",
        "\n",
        "            agent.record_episode(episode, stats['wins'], stats['losses'], stats['draws'])\n",
        "            stats = {'wins': 0, 'losses': 0, 'draws': 0}  # Reset\n",
        "\n",
        "    return agent\n",
        "\n",
        "def play_against_agent(agent):\n",
        "    \"\"\"Interactive game between human and trained agent\"\"\"\n",
        "    env = TicTacToe()\n",
        "    state = env.reset()\n",
        "\n",
        "    print(\"You are O (second player). The agent is X (first player).\")\n",
        "    print(\"Enter moves as numbers corresponding to board positions:\")\n",
        "    env.render()\n",
        "\n",
        "    # Agent moves first\n",
        "    print(\"Agent's turn...\")\n",
        "    sleep(1)\n",
        "    available = env.available_actions()\n",
        "    action = agent.choose_action(state, available, training=False)\n",
        "    state, _, done = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "    while not done:\n",
        "        # My move\n",
        "        while True:\n",
        "            try:\n",
        "                move = int(input(\"Your move (enter position number): \"))\n",
        "                if move not in env.available_actions():\n",
        "                    print(\"Invalid move! Try again.\")\n",
        "                    continue\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Please enter a number corresponding to an empty position.\")\n",
        "\n",
        "        state, _, done = env.step(move)\n",
        "        env.render()\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Agent move\n",
        "        print(\"Agent's turn...\")\n",
        "        sleep(1)\n",
        "        available = env.available_actions()\n",
        "        action = agent.choose_action(state, available, training=False)\n",
        "        state, _, done = env.step(action)\n",
        "        env.render()\n",
        "\n",
        "    # Game over\n",
        "    if env.winner == 1:\n",
        "        print(\"Agent (X) wins! üß†\")\n",
        "    elif env.winner == -1:\n",
        "        print(\"You (O) win! üéâ\")\n",
        "    else:\n",
        "        print(\"It's a draw! ü§ù\")\n",
        "\n",
        "\n",
        "print(\"Training agent against random opponent...\")\n",
        "agent = train_agent(episodes=20000)\n",
        "agent.plot_training()\n",
        "\n",
        "print(\"\\nTraining complete! Now you can play against the agent.\")\n",
        "play_against_agent(agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWF3ke07jAWe"
      },
      "source": [
        "#FEEDBACK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKSLtN9izqH"
      },
      "source": [
        "**The main issue in the code is that the agent learns from transitions that include the opponent's move, which confuses the learning process. The agent should learn immediately after its own actions for cleaner learning signals.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8XP3cyeehfq"
      },
      "source": [
        "#Now the problem with this one is that its not smart at all, Yes the user experience is improved but the Agent is not smart. Lets improve that...To improve this we use Deep Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#It's still not smart.... so I did research and te solution is Deep-Learning.\n"
      ],
      "metadata": {
        "id": "eQHsDR_90ynL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, deque\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "from enum import Enum\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Player(Enum):\n",
        "    X = 1\n",
        "    O = -1\n",
        "    EMPTY = 0\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.full((3, 3), Player.EMPTY.value, dtype=int)\n",
        "        self.current_player = Player.X\n",
        "        self.done = False\n",
        "        self.winner = None\n",
        "        self.move_history = []\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return tuple(self.board.ravel())\n",
        "\n",
        "    def get_state_tensor(self):\n",
        "        \"\"\"Convert board state to tensor format for neural network\"\"\"\n",
        "        # Create a 3-channel representation: [X positions, O positions, Empty positions]\n",
        "        state = np.zeros((3, 3, 3), dtype=np.float32)\n",
        "\n",
        "        # Channel 0: X positions\n",
        "        state[:, :, 0] = (self.board == Player.X.value).astype(np.float32)\n",
        "        # Channel 1: O positions\n",
        "        state[:, :, 1] = (self.board == Player.O.value).astype(np.float32)\n",
        "        # Channel 2: Empty positions\n",
        "        state[:, :, 2] = (self.board == Player.EMPTY.value).astype(np.float32)\n",
        "\n",
        "        return torch.FloatTensor(state.flatten())\n",
        "\n",
        "    def available_actions(self):\n",
        "        return [i for i in range(9) if self.board.flat[i] == Player.EMPTY.value]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            return self.get_state(), 0, True\n",
        "\n",
        "        row, col = divmod(action, 3)\n",
        "\n",
        "        if self.board[row, col] != Player.EMPTY.value:\n",
        "            self.done = True\n",
        "            return self.get_state(), -10, True\n",
        "\n",
        "        self.board[row, col] = self.current_player.value\n",
        "        self.move_history.append((action, self.current_player))\n",
        "\n",
        "        if self._check_winner(self.current_player):\n",
        "            self.done = True\n",
        "            self.winner = self.current_player\n",
        "            return self.get_state(), 1, True\n",
        "\n",
        "        if len(self.available_actions()) == 0:\n",
        "            self.done = True\n",
        "            return self.get_state(), 0.1, True\n",
        "\n",
        "        self.current_player = Player.O if self.current_player == Player.X else Player.X\n",
        "        return self.get_state(), 0, False\n",
        "\n",
        "    def _check_winner(self, player):\n",
        "        board = self.board\n",
        "        for i in range(3):\n",
        "            if all(board[i, :] == player.value) or all(board[:, i] == player.value):\n",
        "                return True\n",
        "        if (board[0, 0] == board[1, 1] == board[2, 2] == player.value or\n",
        "            board[0, 2] == board[1, 1] == board[2, 0] == player.value):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def get_strategic_positions(self, player):\n",
        "        winning_moves = []\n",
        "        blocking_moves = []\n",
        "        fork_moves = []\n",
        "        opponent = Player.O if player == Player.X else Player.X\n",
        "\n",
        "        for action in self.available_actions():\n",
        "            row, col = divmod(action, 3)\n",
        "\n",
        "            # Check winning moves\n",
        "            self.board[row, col] = player.value\n",
        "            if self._check_winner(player):\n",
        "                winning_moves.append(action)\n",
        "            self.board[row, col] = Player.EMPTY.value\n",
        "\n",
        "            # Check blocking moves\n",
        "            self.board[row, col] = opponent.value\n",
        "            if self._check_winner(opponent):\n",
        "                blocking_moves.append(action)\n",
        "            self.board[row, col] = Player.EMPTY.value\n",
        "\n",
        "            # Check fork opportunities (simplified version)\n",
        "            if action in [0, 2, 6, 8, 4]:  # Corners and center\n",
        "                winning_paths = 0\n",
        "                # Check rows\n",
        "                temp_row = self.board[row, :].copy()\n",
        "                temp_row[col] = player.value\n",
        "                if sum(temp_row == player.value) == 2 and Player.EMPTY.value in temp_row:\n",
        "                    winning_paths += 1\n",
        "                # Check columns\n",
        "                temp_col = self.board[:, col].copy()\n",
        "                temp_col[row] = player.value\n",
        "                if sum(temp_col == player.value) == 2 and Player.EMPTY.value in temp_col:\n",
        "                    winning_paths += 1\n",
        "                # Check diagonals if applicable\n",
        "                if (row == col) or (row + col == 2):\n",
        "                    if row == col:  # Main diagonal\n",
        "                        temp_diag = np.diag(self.board).copy()\n",
        "                        temp_diag[row] = player.value\n",
        "                        if sum(temp_diag == player.value) == 2 and Player.EMPTY.value in temp_diag:\n",
        "                            winning_paths += 1\n",
        "                    if row + col == 2:  # Anti-diagonal\n",
        "                        temp_anti = np.diag(np.fliplr(self.board)).copy()\n",
        "                        temp_anti[2 - col] = player.value\n",
        "                        if sum(temp_anti == player.value) == 2 and Player.EMPTY.value in temp_anti:\n",
        "                            winning_paths += 1\n",
        "                if winning_paths >= 2:\n",
        "                    fork_moves.append(action)\n",
        "\n",
        "        return winning_moves, blocking_moves, fork_moves\n",
        "\n",
        "    def render(self, show_help=True):\n",
        "        symbols = {\n",
        "            Player.X.value: 'X',\n",
        "            Player.O.value: 'O',\n",
        "            Player.EMPTY.value: ' '\n",
        "        }\n",
        "\n",
        "        print(\"\\n  0 | 1 | 2\")\n",
        "        print(\"  --|---|--\")\n",
        "        for i in range(3):\n",
        "            row_display = []\n",
        "            for j in range(3):\n",
        "                pos = i * 3 + j\n",
        "                cell = self.board[i, j]\n",
        "                if cell == Player.EMPTY.value:\n",
        "                    row_display.append(str(pos))\n",
        "                else:\n",
        "                    row_display.append(symbols[cell])\n",
        "            print(f\"{i} {' | '.join(row_display)}\")\n",
        "            if i < 2:\n",
        "                print(\"  --|---|--\")\n",
        "\n",
        "        if not self.done:\n",
        "            print(f\"\\nCurrent player: {self.current_player.name}\")\n",
        "            if show_help:\n",
        "                print(f\"Available moves: {self.available_actions()}\")\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Deep Q-Network for Tic-Tac-Toe\"\"\"\n",
        "\n",
        "    def __init__(self, input_size=27, hidden_sizes=[256, 256, 128, 64], output_size=9):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        # Build the network layers\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.2)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_size, output_size))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Experience replay buffer for DQN\"\"\"\n",
        "\n",
        "    def __init__(self, capacity=20000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        return (torch.stack(states),\n",
        "                torch.LongTensor(actions),\n",
        "                torch.FloatTensor(rewards),\n",
        "                torch.stack(next_states),\n",
        "                torch.BoolTensor(dones))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class DeepQLearningAgent:\n",
        "    def __init__(self, lr=0.0005, gamma=0.99, epsilon=1.0,\n",
        "                 epsilon_decay=0.9997, epsilon_min=0.02,\n",
        "                 batch_size=64, memory_size=20000, target_update=200):\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update = target_update\n",
        "\n",
        "        # Neural networks\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.q_network = DQN().to(self.device)\n",
        "        self.target_network = DQN().to(self.device)\n",
        "\n",
        "        # Optimizer with weight decay\n",
        "        self.optimizer = optim.AdamW(self.q_network.parameters(), lr=lr, weight_decay=1e-4)\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10000, gamma=0.9)\n",
        "\n",
        "        # Experience replay\n",
        "        self.memory = ReplayBuffer(memory_size)\n",
        "\n",
        "        # Training metrics\n",
        "        self.training_history = []\n",
        "        self.steps_done = 0\n",
        "        self.player = Player.X\n",
        "\n",
        "        # Copy weights to target network\n",
        "        self.update_target_network()\n",
        "\n",
        "        print(f\"üß† Enhanced Deep Q-Network initialized\")\n",
        "        print(f\"   Device: {self.device}\")\n",
        "        print(f\"   Network: {sum(p.numel() for p in self.q_network.parameters())} parameters\")\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Copy weights from main network to target network\"\"\"\n",
        "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
        "\n",
        "    def get_q_values(self, state):\n",
        "        \"\"\"Get Q-values for a state\"\"\"\n",
        "        if isinstance(state, tuple):\n",
        "            # Convert tuple state to tensor\n",
        "            env = TicTacToe()\n",
        "            env.board = np.array(state).reshape(3, 3)\n",
        "            state_tensor = env.get_state_tensor()\n",
        "        else:\n",
        "            state_tensor = state\n",
        "\n",
        "        with torch.no_grad():\n",
        "            state_tensor = state_tensor.unsqueeze(0).to(self.device)\n",
        "            q_values = self.q_network(state_tensor)\n",
        "            return q_values.squeeze().cpu().numpy()\n",
        "\n",
        "    def choose_action(self, state, available_actions, training=True):\n",
        "        if not available_actions:\n",
        "            return None\n",
        "\n",
        "        # Strategic exploration during training\n",
        "        if training and np.random.random() < self.epsilon:\n",
        "            # Use strategic exploration like in the original agent\n",
        "            env = TicTacToe()\n",
        "            if isinstance(state, tuple):\n",
        "                env.board = np.array(state).reshape(3, 3)\n",
        "            env.current_player = self.player\n",
        "\n",
        "            winning_moves, blocking_moves, fork_moves = env.get_strategic_positions(self.player)\n",
        "\n",
        "            if winning_moves:\n",
        "                return random.choice(winning_moves)\n",
        "            if blocking_moves:\n",
        "                return random.choice(blocking_moves)\n",
        "            if fork_moves:\n",
        "                return random.choice(fork_moves)\n",
        "\n",
        "            # Prefer center and corners during exploration\n",
        "            preferred = [a for a in available_actions if a in [0, 2, 6, 8, 4]]\n",
        "            if preferred:\n",
        "                return random.choice(preferred)\n",
        "\n",
        "            return random.choice(available_actions)\n",
        "\n",
        "        # Exploitation using neural network\n",
        "        q_values = self.get_q_values(state)\n",
        "\n",
        "        # Mask unavailable actions\n",
        "        masked_q_values = np.full(9, -np.inf)\n",
        "        for action in available_actions:\n",
        "            masked_q_values[action] = q_values[action]\n",
        "\n",
        "        return np.argmax(masked_q_values)\n",
        "\n",
        "    def learn(self):\n",
        "        \"\"\"Train the network using experience replay with improvements\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        # Sample a batch of experiences\n",
        "        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
        "\n",
        "        states = states.to(self.device)\n",
        "        actions = actions.to(self.device)\n",
        "        rewards = rewards.to(self.device)\n",
        "        next_states = next_states.to(self.device)\n",
        "        dones = dones.to(self.device)\n",
        "\n",
        "        # Current Q-values\n",
        "        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))\n",
        "\n",
        "        # Double DQN: use main network to select actions, target network to evaluate\n",
        "        with torch.no_grad():\n",
        "            next_actions = self.q_network(next_states).max(1)[1]\n",
        "            next_q_values = self.target_network(next_states).gather(1, next_actions.unsqueeze(1)).squeeze()\n",
        "            target_q_values = rewards + (self.gamma * next_q_values * ~dones)\n",
        "\n",
        "        # Compute Huber loss (more robust than MSE)\n",
        "        loss = F.smooth_l1_loss(current_q_values.squeeze(), target_q_values)\n",
        "\n",
        "        # Optimize\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(self.q_network.parameters(), 1.0)\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Update target network periodically\n",
        "        self.steps_done += 1\n",
        "        if self.steps_done % self.target_update == 0:\n",
        "            self.update_target_network()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "    def save(self, filename):\n",
        "        torch.save({\n",
        "            'q_network_state_dict': self.q_network.state_dict(),\n",
        "            'target_network_state_dict': self.target_network.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'params': {\n",
        "                'lr': self.lr,\n",
        "                'gamma': self.gamma,\n",
        "                'epsilon': self.epsilon,\n",
        "                'epsilon_decay': self.epsilon_decay,\n",
        "                'epsilon_min': self.epsilon_min,\n",
        "                'batch_size': self.batch_size,\n",
        "                'target_update': self.target_update\n",
        "            },\n",
        "            'training_history': self.training_history,\n",
        "            'steps_done': self.steps_done\n",
        "        }, filename)\n",
        "        print(f\"üíæ Deep agent saved to {filename}\")\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, filename):\n",
        "        checkpoint = torch.load(filename, map_location='cpu')\n",
        "\n",
        "        agent = cls(**checkpoint['params'])\n",
        "        agent.q_network.load_state_dict(checkpoint['q_network_state_dict'])\n",
        "        agent.target_network.load_state_dict(checkpoint['target_network_state_dict'])\n",
        "        agent.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        agent.training_history = checkpoint['training_history']\n",
        "        agent.steps_done = checkpoint['steps_done']\n",
        "\n",
        "        print(f\"üìÅ Deep agent loaded from {filename}\")\n",
        "        return agent\n",
        "\n",
        "def train_deep_agent(episodes=50000, save_path=\"deep_ttt_agent.pth\"):\n",
        "    env = TicTacToe()\n",
        "    agent = DeepQLearningAgent()\n",
        "\n",
        "    # Progressive opponents\n",
        "    opponents = [\n",
        "        SmartRandomOpponent(skill_level=0.3),  # Beginner\n",
        "        SmartRandomOpponent(skill_level=0.6),  # Intermediate\n",
        "        SmartRandomOpponent(skill_level=0.9)   # Advanced\n",
        "    ]\n",
        "\n",
        "    stats = {'wins': 0, 'losses': 0, 'draws': 0}\n",
        "    losses = []\n",
        "\n",
        "    print(\"üöÄ Training Deep Q-Network agent...\")\n",
        "    print(f\"Episodes: {episodes:,}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for episode in range(1, episodes + 1):\n",
        "        # Progressively harder opponents\n",
        "        if episode < episodes * 0.3:\n",
        "            opponent = opponents[0]\n",
        "        elif episode < episodes * 0.7:\n",
        "            opponent = opponents[1]\n",
        "        else:\n",
        "            opponent = opponents[2]\n",
        "\n",
        "        env.reset()\n",
        "\n",
        "        while not env.done:\n",
        "            if env.current_player == Player.X:  # Agent's turn\n",
        "                state = env.get_state_tensor()\n",
        "                available = env.available_actions()\n",
        "\n",
        "                action = agent.choose_action(state, available, training=True)\n",
        "                next_state_tuple, reward, done = env.step(action)\n",
        "                next_state = env.get_state_tensor()\n",
        "\n",
        "                # Additional reward for strategic positions\n",
        "                if action == 4:  # Center\n",
        "                    reward += 0.3\n",
        "                elif action in [0, 2, 6, 8]:  # Corners\n",
        "                    reward += 0.2\n",
        "\n",
        "                # Store experience in replay buffer\n",
        "                agent.memory.push(state, action, reward, next_state, done)\n",
        "\n",
        "                # Train the network\n",
        "                if len(agent.memory) >= agent.batch_size:\n",
        "                    loss = agent.learn()\n",
        "                    if loss is not None:\n",
        "                        losses.append(loss)\n",
        "\n",
        "            else:  # Opponent's turn\n",
        "                action = opponent.choose_action(env)\n",
        "                if action is not None:\n",
        "                    env.step(action)\n",
        "\n",
        "        # Game outcome tracking\n",
        "        if env.winner == Player.X:\n",
        "            stats['wins'] += 1\n",
        "        elif env.winner == Player.O:\n",
        "            stats['losses'] += 1\n",
        "        else:\n",
        "            stats['draws'] += 1\n",
        "\n",
        "        agent.decay_epsilon()\n",
        "\n",
        "        # Progress reporting\n",
        "        if episode % 2500 == 0 or episode == episodes:\n",
        "            total = max(1, stats['wins'] + stats['losses'] + stats['draws'])\n",
        "            win_rate = stats['wins'] / total\n",
        "            loss_rate = stats['losses'] / total\n",
        "            draw_rate = stats['draws'] / total\n",
        "            avg_loss = np.mean(losses[-1000:]) if losses else 0\n",
        "\n",
        "            agent.training_history.append({\n",
        "                'episode': episode,\n",
        "                'win_rate': win_rate,\n",
        "                'epsilon': agent.epsilon,\n",
        "                'avg_loss': avg_loss,\n",
        "                'memory_size': len(agent.memory)\n",
        "            })\n",
        "\n",
        "            print(f\"Episode {episode:,}\")\n",
        "            print(f\"  Win rate: {win_rate:.1%}  Loss rate: {loss_rate:.1%}  Draw rate: {draw_rate:.1%}\")\n",
        "            print(f\"  Exploration: {agent.epsilon:.4f}  Avg Loss: {avg_loss:.6f}\")\n",
        "            print(f\"  Memory size: {len(agent.memory):,}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "            stats = {'wins': 0, 'losses': 0, 'draws': 0}\n",
        "\n",
        "    if save_path:\n",
        "        agent.save(save_path)\n",
        "        print(f\"üíæ Saved trained deep agent to {save_path}\")\n",
        "\n",
        "    return agent\n",
        "\n",
        "def main():\n",
        "    print(\"üß† Deep Q-Learning Tic-Tac-Toe AI\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    agent_file = \"deep_ttt_agent.pth\"\n",
        "    agent = None\n",
        "\n",
        "    if os.path.exists(agent_file):\n",
        "        try:\n",
        "            agent = DeepQLearningAgent.load(agent_file)\n",
        "            print(f\"‚úÖ Loaded trained deep agent from {agent_file}\")\n",
        "            print(f\"  Memory size: {len(agent.memory):,} experiences\")\n",
        "            print(f\"  Current Œµ: {agent.epsilon:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading agent: {e}\")\n",
        "            agent = None\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(\"Main Menu:\")\n",
        "        print(\"1. Train new deep agent\")\n",
        "        print(\"2. Evaluate deep agent\")\n",
        "        print(\"3. Play against deep agent\")\n",
        "        print(\"4. View training history\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"Select option (1-5): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            try:\n",
        "                episodes = int(input(\"Training episodes (default 50000): \") or 50000)\n",
        "                agent = train_deep_agent(episodes=episodes)\n",
        "                plot_deep_training(agent.training_history)\n",
        "            except ValueError:\n",
        "                print(\"Invalid input! Using default 50000 episodes\")\n",
        "                agent = train_deep_agent()\n",
        "                plot_deep_training(agent.training_history)\n",
        "\n",
        "        elif choice == '2':\n",
        "            if agent is None:\n",
        "                print(\"No agent loaded! Please train or load an agent first.\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                games = int(input(\"Evaluation games (default 1000): \") or 1000)\n",
        "                level = float(input(\"Opponent skill level (0.1-1.0, default 0.8): \") or 0.8)\n",
        "                evaluate_deep_agent(agent, games=games, opponent_level=level)\n",
        "            except ValueError:\n",
        "                print(\"Invalid input! Using defaults\")\n",
        "                evaluate_deep_agent(agent)\n",
        "\n",
        "        elif choice == '3':\n",
        "            if agent is None:\n",
        "                print(\"No agent loaded! Please train or load an agent first.\")\n",
        "                continue\n",
        "\n",
        "            while True:\n",
        "                first = input(\"Go first? (y/n): \").lower().strip()\n",
        "                if first in ['y', 'n']:\n",
        "                    play_interactive_deep(agent, human_first=(first == 'y'))\n",
        "                    break\n",
        "                print(\"Please enter 'y' or 'n'\")\n",
        "\n",
        "            if input(\"Play again? (y/n): \").lower() != 'y':\n",
        "                continue\n",
        "\n",
        "        elif choice == '4':\n",
        "            if agent and agent.training_history:\n",
        "                plot_deep_training(agent.training_history)\n",
        "            else:\n",
        "                print(\"No training history available!\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice! Please enter 1-5\")\n",
        "\n",
        "    print(\"\\nüëã Thanks for playing!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "iAyXxQDKBQTR",
        "outputId": "44891e72-fc8a-4e03-996f-c33e6223cea7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Deep Q-Learning Tic-Tac-Toe AI\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "Main Menu:\n",
            "1. Train new deep agent\n",
            "2. Evaluate deep agent\n",
            "3. Play against deep agent\n",
            "4. View training history\n",
            "5. Exit\n",
            "Select option (1-5): 3\n",
            "No agent loaded! Please train or load an agent first.\n",
            "\n",
            "========================================\n",
            "Main Menu:\n",
            "1. Train new deep agent\n",
            "2. Evaluate deep agent\n",
            "3. Play against deep agent\n",
            "4. View training history\n",
            "5. Exit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a52d5546dad3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-a52d5546dad3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5. Exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Select option (1-5): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUA7WqBdqn2pZzSGd6IOhi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}